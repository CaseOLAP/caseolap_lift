{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263c660a",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716bd690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grape in /home/ubuntu/anaconda3/lib/python3.9/site-packages (0.1.24)\n",
      "Requirement already satisfied: embiggen>=0.11.37 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from grape) (0.11.38)\n",
      "Requirement already satisfied: ensmallen>=0.8.24 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from grape) (0.8.24)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.20.3)\n",
      "Requirement already satisfied: keras-mixed-sequence>=1.0.28 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.0.28)\n",
      "Requirement already satisfied: dict-hash>=1.1.29 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.1.29)\n",
      "Requirement already satisfied: sanitize-ml-labels>=1.0.45 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.0.49)\n",
      "Requirement already satisfied: environments-utils>=1.0.6 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.0.6)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (21.0)\n",
      "Requirement already satisfied: compress-pickle>=2.1.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (0.24.2)\n",
      "Requirement already satisfied: matplotlib>=3.5.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (3.5.2)\n",
      "Requirement already satisfied: userinput>=1.0.19 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.0.19)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (4.62.3)\n",
      "Requirement already satisfied: validate-version-code in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.0.4)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.3.4)\n",
      "Requirement already satisfied: cache-decorator>=2.1.11 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (2.1.11)\n",
      "Requirement already satisfied: ddd-subplots>=1.0.23 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from embiggen>=0.11.37->grape) (1.0.23)\n",
      "Requirement already satisfied: humanize>=3.4.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from cache-decorator>=2.1.11->embiggen>=0.11.37->grape) (4.2.3)\n",
      "Requirement already satisfied: deflate-dict in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from cache-decorator>=2.1.11->embiggen>=0.11.37->grape) (1.0.9)\n",
      "Requirement already satisfied: compress-json>=1.0.4 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from cache-decorator>=2.1.11->embiggen>=0.11.37->grape) (1.0.7)\n",
      "Requirement already satisfied: imageio in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ddd-subplots>=1.0.23->embiggen>=0.11.37->grape) (2.9.0)\n",
      "Requirement already satisfied: pygifsicle in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ddd-subplots>=1.0.23->embiggen>=0.11.37->grape) (1.0.5)\n",
      "Requirement already satisfied: sklearn in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ddd-subplots>=1.0.23->embiggen>=0.11.37->grape) (0.0)\n",
      "Requirement already satisfied: support-developer in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ddd-subplots>=1.0.23->embiggen>=0.11.37->grape) (1.0.4)\n",
      "Requirement already satisfied: opencv-python in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ddd-subplots>=1.0.23->embiggen>=0.11.37->grape) (4.6.0.66)\n",
      "Requirement already satisfied: toml~=0.10.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ensmallen>=0.8.24->grape) (0.10.2)\n",
      "Requirement already satisfied: downloaders>=1.0.15 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ensmallen>=0.8.24->grape) (1.0.15)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ensmallen>=0.8.24->grape) (8.0.0)\n",
      "Requirement already satisfied: bioregistry>=0.5.65 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ensmallen>=0.8.24->grape) (0.5.75)\n",
      "Requirement already satisfied: pydantic in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (1.9.1)\n",
      "Requirement already satisfied: more-click in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (0.1.1)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (8.0.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (2.28.1)\n",
      "Requirement already satisfied: pystow>=0.1.13 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (0.4.6)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.5.2->embiggen>=0.11.37->grape) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.5.2->embiggen>=0.11.37->grape) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.5.2->embiggen>=0.11.37->grape) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.5.2->embiggen>=0.11.37->grape) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.5.2->embiggen>=0.11.37->grape) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.5.2->embiggen>=0.11.37->grape) (2.8.2)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.5.2->embiggen>=0.11.37->grape) (1.16.0)\n",
      "Requirement already satisfied: validators in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from userinput>=1.0.19->embiggen>=0.11.37->grape) (0.20.0)\n",
      "Requirement already satisfied: ipython in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from userinput>=1.0.19->embiggen>=0.11.37->grape) (7.29.0)\n",
      "Requirement already satisfied: jaro-winkler in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from userinput>=1.0.19->embiggen>=0.11.37->grape) (2.0.0)\n",
      "Requirement already satisfied: validate-email in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from userinput>=1.0.19->embiggen>=0.11.37->grape) (1.3)\n",
      "Requirement already satisfied: IPy in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from userinput>=1.0.19->embiggen>=0.11.37->grape) (1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (0.18.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (58.0.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (0.1.2)\n",
      "Requirement already satisfied: decorator in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (5.1.0)\n",
      "Requirement already satisfied: backcall in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (0.2.0)\n",
      "Requirement already satisfied: pygments in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (3.0.20)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (0.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->userinput>=1.0.19->embiggen>=0.11.37->grape) (0.2.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from pandas->embiggen>=0.11.37->grape) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from pydantic->bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (1.25.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->bioregistry>=0.5.65->ensmallen>=0.8.24->grape) (2021.10.8)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from scikit-learn->embiggen>=0.11.37->grape) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from scikit-learn->embiggen>=0.11.37->grape) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from scikit-learn->embiggen>=0.11.37->grape) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U grape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630ff5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grape==0.1.24\n",
      "embiggen==0.11.38\n",
      "ensmallen==0.8.24\n"
     ]
    }
   ],
   "source": [
    "! pip freeze | grep \"grape\"\n",
    "! pip freeze | grep \"embiggen\"\n",
    "! pip freeze | grep \"ensmallen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f45c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 05:07:23.093980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-02 05:07:23.094038: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from grape import Graph\n",
    "import pandas as pd\n",
    "\n",
    "from grape.edge_prediction import PerceptronEdgePrediction\n",
    "from grape.embedders import FirstOrderLINEEnsmallen\n",
    "# from grape.datasets.string import HomoSapiens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c799dddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_edge_list.tsv  merged_node_list.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb656de6",
   "metadata": {},
   "source": [
    "## Independent evaluation of different edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cad47cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column 'edge_type' is not present in the header:\n [\"head\", \"relation\", \"tail\", \"weight\"]\nNote that the separator used was `\t`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10923/4248247965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m g = Graph.from_csv(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mdirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnode_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./input/merged_node_list.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0medge_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./input/merged_edge_list.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The column 'edge_type' is not present in the header:\n [\"head\", \"relation\", \"tail\", \"weight\"]\nNote that the separator used was `\t`."
     ]
    }
   ],
   "source": [
    "g = Graph.from_csv(\n",
    "  directed=False, \n",
    "  node_path='./input/merged_node_list.tsv',\n",
    "  edge_path='./input/merged_edge_list.tsv',\n",
    "  verbose=True,\n",
    "  nodes_column='node',\n",
    "  node_list_node_types_column='node_type',\n",
    "  default_node_type='None',\n",
    "  sources_column='head',\n",
    "  destinations_column='tail',\n",
    "  edge_list_edge_types_column='edge_type',\n",
    "  name=\"CVD KG\"\n",
    ")\n",
    "g = g.remove_disconnected_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bf593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_protein_group': 61142,\n",
       " 'ClinVar': 3920,\n",
       " 'interacts_with': 373456,\n",
       " 'MeSH_hierarchy': 25454,\n",
       " 'MeSH_is': 25952,\n",
       " 'ClinGen': 12988,\n",
       " 'is_gene_product': 75888,\n",
       " 'MeSH_CVD': 38,\n",
       " 'in_species_cardiac_proteome': 56058,\n",
       " 'CaseOLAP_score': 62320,\n",
       " 'participates_in_pathway': 360594}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many of each edge type?\n",
    "g.get_edge_type_names_counts_hashmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d025649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_predictions_with_ground_truth(pred_df, test_graph, return_bool = True):\n",
    "    test_edges = pd.DataFrame(test_graph.get_edge_node_names(directed=False))\n",
    "    test_edges.columns = ['sources','destinations']\n",
    "    \n",
    "    labeled_pred_df = pred_df.merge(test_edges,how='left',indicator=True)\n",
    "    test_truth = []\n",
    "    for b in labeled_pred_df['_merge'] == 'both':\n",
    "        if return_bool:\n",
    "            y_ = b\n",
    "        else:\n",
    "            # return 1 or 0\n",
    "            y_ = 1 if b else 0\n",
    "        test_truth += [y_]\n",
    "    labeled_pred_df['ground_truth'] = test_truth\n",
    "    labeled_pred_df = labeled_pred_df.drop('_merge', axis=1)\n",
    "    return labeled_pred_df\n",
    "\n",
    "\n",
    "def label_negative_sample_pred(pred_df):\n",
    "    pred_df['ground_truth'] = False\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def evaluate_predictions(m, labeled_pred_df):\n",
    "    # convert DataFrame to numpy used for evaluation\n",
    "    y_label = labeled_pred_df['ground_truth'].to_numpy()\n",
    "    y_score = labeled_pred_df['predictions'].to_numpy()\n",
    "    \n",
    "    # handle case where no ground truth (for negative sampled edges)\n",
    "    all_false = len(set(y_label)) == 1 and (~y_label[0])\n",
    "    if all_false:\n",
    "        e1 = {'auroc':float('NaN'),'auprc':float('NaN')}\n",
    "    else:\n",
    "        e1 = m.evaluate_prediction_probabilities(y_label,y_score)\n",
    "    e2 = m.evaluate_predictions(y_label,y_score)\n",
    "    return e1 | e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27508107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_species_cardiac_proteome': [('Gene', 'Species')],\n",
       " 'in_protein_group': [('Protein', 'UniRef90_Protein_Group')],\n",
       " 'participates_in_pathway': [('Protein', 'Reactome_Pathway')],\n",
       " 'MeSH_hierarchy': [('MeSH_Tree_Disease', 'MeSH_Tree_Disease')],\n",
       " 'MeSH_is': [('MeSH_Disease', 'MeSH_Tree_Disease')],\n",
       " 'MeSH_CVD': [('CVD', 'MeSH_Tree_Disease')],\n",
       " 'interacts_with': [('Protein', 'Protein')],\n",
       " 'is_gene_product': [('Gene', 'Protein')],\n",
       " 'ClinVar': [('MeSH_Disease', 'Protein')],\n",
       " 'CaseOLAP_score': [('CVD', 'UniRef90_Protein_Group')],\n",
       " 'ClinGen': [('MeSH_Disease', 'Protein')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_edge_type_to_node_types_mapping(g, directed=False):\n",
    "    '''\n",
    "    This function returns a mapping from edge_type -> (from_types,to_types)\n",
    "    '''\n",
    "    # gather node and edge types for every edge as a DataFrame\n",
    "    edge_to_type_dict = {h:[] for h in [\"from\",\"to\",\"from_type\",\"to_type\",\"edge_type\"]}\n",
    "    for from_node_id,to_node_id in g.get_edge_node_ids(directed=False):\n",
    "        # get node types\n",
    "        from_node_type_ids = g.get_node_type_ids_from_node_id(from_node_id)\n",
    "        from_node_type = [g.get_node_type_name_from_node_type_id(i) for i in from_node_type_ids]\n",
    "        to_node_type_ids = g.get_node_type_ids_from_node_id(to_node_id)\n",
    "        to_node_type =  [g.get_node_type_name_from_node_type_id(i) for i in to_node_type_ids]\n",
    "\n",
    "        # get edge type\n",
    "        edge_id = g.get_edge_id_from_node_ids(from_node_id,to_node_id)\n",
    "        edge_type = g.get_edge_type_name_from_edge_id(edge_id)\n",
    "\n",
    "        # append to dict\n",
    "        edge_to_type_dict['from'] += [from_node_id]\n",
    "        edge_to_type_dict['to'] += [to_node_id]\n",
    "        edge_to_type_dict['from_type'] += [from_node_type]\n",
    "        edge_to_type_dict['to_type'] += [to_node_type]\n",
    "        edge_to_type_dict['edge_type'] += [edge_type]\n",
    "    edge_to_type_df = pd.DataFrame(edge_to_type_dict)\n",
    "\n",
    "    # take unique node types for each edge type\n",
    "    edge_type_to_node_types = {}\n",
    "    for edge_type in set(edge_to_type_df['edge_type']):\n",
    "        # only rows with the specified edge_type\n",
    "        sub_df = edge_to_type_df[edge_to_type_df['edge_type'] == edge_type]\n",
    "        \n",
    "        # get unique pairs of node types\n",
    "        unique_node_type_pairs = set()\n",
    "        for from_node_types, to_node_types in zip(sub_df['from_type'],sub_df['to_type']):\n",
    "            # enumerate all pairs, since these are lists of node types\n",
    "            pairs = [(f,t) for f in from_node_types for t in to_node_types]\n",
    "            \n",
    "            # if undirected, do not include reverse node type \n",
    "            # i.e. include (type_1,type_2) but not (type_2,type_1)\n",
    "            if not directed:                \n",
    "                pairs_sorted = set()\n",
    "                for f,t in pairs:\n",
    "                    # sort pair alphabetically\n",
    "                    pair = (f,t) if (f < t) else (t,f) \n",
    "                    # keep unique pairs\n",
    "                    pairs_sorted.add(pair)\n",
    "                pairs = pairs_sorted\n",
    "                \n",
    "            # add unique pairs\n",
    "            unique_node_type_pairs = unique_node_type_pairs.union(pairs)\n",
    "            \n",
    "        edge_type_to_node_types[edge_type] = list(unique_node_type_pairs)\n",
    "    return edge_type_to_node_types\n",
    "\n",
    "edge_type_to_node_types_mapping = get_edge_type_to_node_types_mapping(g,directed=False)\n",
    "edge_type_to_node_types_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9623935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CVD'] ['UniRef90_Protein_Group']\n",
      "<embiggen.edge_prediction.edge_prediction_ensmallen.perceptron.PerceptronEdgePrediction object at 0x7f9cbcb927f0>\n",
      "<embiggen.edge_prediction.edge_prediction_ensmallen.perceptron.PerceptronEdgePrediction object at 0x7f9cbcb927f0>\n",
      "<embiggen.edge_prediction.edge_prediction_ensmallen.perceptron.PerceptronEdgePrediction object at 0x7f9cbcb927f0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>markedness</th>\n",
       "      <th>informedness</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>prevalence_threshold</th>\n",
       "      <th>negative_predictive_value</th>\n",
       "      <th>positive_likelyhood_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>false_omission_rate</th>\n",
       "      <th>diagnostic_odds_ratio</th>\n",
       "      <th>matthews_correlation_coefficient</th>\n",
       "      <th>false_discovery_rate</th>\n",
       "      <th>fall_out</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fowlkes_mallows_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.873651</td>\n",
       "      <td>0.311496</td>\n",
       "      <td>0.192625</td>\n",
       "      <td>0.618093</td>\n",
       "      <td>0.987636</td>\n",
       "      <td>0.630457</td>\n",
       "      <td>0.809047</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>0.998233</td>\n",
       "      <td>2.672586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>136.282171</td>\n",
       "      <td>0.345051</td>\n",
       "      <td>0.805608</td>\n",
       "      <td>0.369543</td>\n",
       "      <td>0.082810</td>\n",
       "      <td>0.194392</td>\n",
       "      <td>0.660035</td>\n",
       "      <td>0.324846</td>\n",
       "      <td>0.438165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.757725</td>\n",
       "      <td>0.076638</td>\n",
       "      <td>0.054756</td>\n",
       "      <td>0.438936</td>\n",
       "      <td>0.845886</td>\n",
       "      <td>0.593050</td>\n",
       "      <td>0.719468</td>\n",
       "      <td>0.409545</td>\n",
       "      <td>0.991649</td>\n",
       "      <td>2.078599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>7.998707</td>\n",
       "      <td>0.155030</td>\n",
       "      <td>0.936893</td>\n",
       "      <td>0.406950</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.063107</td>\n",
       "      <td>0.600986</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.231043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      auroc     auprc  markedness  informedness    recall  specificity  \\\n",
       "0  0.873651  0.311496    0.192625      0.618093  0.987636     0.630457   \n",
       "1  0.757725  0.076638    0.054756      0.438936  0.845886     0.593050   \n",
       "2       NaN       NaN    0.000000           NaN       NaN     0.579273   \n",
       "\n",
       "   balanced_accuracy  prevalence_threshold  negative_predictive_value  \\\n",
       "0           0.809047              0.379535                   0.998233   \n",
       "1           0.719468              0.409545                   0.991649   \n",
       "2                NaN                   NaN                   1.000000   \n",
       "\n",
       "   positive_likelyhood_ratio  ...  false_omission_rate  diagnostic_odds_ratio  \\\n",
       "0                   2.672586  ...             0.001767             136.282171   \n",
       "1                   2.078599  ...             0.008351               7.998707   \n",
       "2                        NaN  ...             0.000000                    NaN   \n",
       "\n",
       "   matthews_correlation_coefficient  false_discovery_rate  fall_out  \\\n",
       "0                          0.345051              0.805608  0.369543   \n",
       "1                          0.155030              0.936893  0.406950   \n",
       "2                               NaN              1.000000  0.420727   \n",
       "\n",
       "   prevalence  precision  accuracy  f1_score  fowlkes_mallows_index  \n",
       "0    0.082810   0.194392  0.660035  0.324846               0.438165  \n",
       "1    0.031388   0.063107  0.600986  0.117451               0.231043  \n",
       "2    0.000000   0.000000  0.579273  0.000000                    NaN  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def independent_edge_evaluation(g, node_types):\n",
    "    \n",
    "    # get the node types we will be predicting edge between\n",
    "    source_node_type_list = [node_types[0]]\n",
    "    destination_node_type_list = [node_types[1]]\n",
    "    print(source_node_type_list,destination_node_type_list)\n",
    "    \n",
    "    # split graph into train/test\n",
    "    train, test = g.connected_holdout(train_size=0.7)\n",
    "\n",
    "    # train embedding on train graph\n",
    "    embedding = FirstOrderLINEEnsmallen().fit_transform(train)\n",
    "\n",
    "    # train model on train graph\n",
    "    model = PerceptronEdgePrediction(\n",
    "        edge_features=None,\n",
    "        number_of_edges_per_mini_batch=32,\n",
    "        edge_embeddings=\"CosineSimilarity\"\n",
    "    )\n",
    "    model.fit(\n",
    "        graph=train, \n",
    "        node_features=embedding\n",
    "    )\n",
    "    \n",
    "    # predictions for train, test, and negative sampled graph\n",
    "    train_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=train, \n",
    "                                        node_features=embedding, \n",
    "                                        source_node_types = source_node_type_list,\n",
    "                                        destination_node_types = destination_node_type_list,\n",
    "                                        return_predictions_dataframe=True\n",
    "                                    )\n",
    "    test_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=test, \n",
    "                                        node_features=embedding, \n",
    "                                        source_node_types = source_node_type_list,\n",
    "                                        destination_node_types = destination_node_type_list,\n",
    "                                        return_predictions_dataframe=True\n",
    "                                    )\n",
    "    negative_sampled_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(\n",
    "                                    graph=g.sample_negative_graph(number_of_negative_samples=test.get_number_of_edges()),\n",
    "                                    node_features=embedding, \n",
    "                                    source_node_types = source_node_type_list,\n",
    "                                    destination_node_types = destination_node_type_list,\n",
    "                                    return_predictions_dataframe=True\n",
    "                                )\n",
    "    \n",
    "    # label predictions\n",
    "    labeled_train_pred_df = label_predictions_with_ground_truth(train_pred_df,train)\n",
    "    labeled_test_pred_df = label_predictions_with_ground_truth(test_pred_df,test)\n",
    "    labeled_negative_sample_pred_df = label_negative_sample_pred(negative_sampled_pred_df)\n",
    "    \n",
    "    # evaluation\n",
    "    data = [evaluate_predictions(model,labeled_train_pred_df),\n",
    "            evaluate_predictions(model,labeled_test_pred_df),\n",
    "            evaluate_predictions(model,labeled_negative_sample_pred_df)]\n",
    "    eval_df = pd.DataFrame(data)\n",
    "    \n",
    "    return eval_df\n",
    "\n",
    "edge_pair = edge_type_to_node_types_mapping['CaseOLAP_score'][0]\n",
    "independent_edge_evaluation(g,edge_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1dc44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc916464",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_caseolap = (edge_type_to_node_types_mapping['CaseOLAP_score'][1],\n",
    "                   edge_type_to_node_types_mapping['CaseOLAP_score'][0])\n",
    "independent_edge_evaluation(g,reverse_caseolap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95996cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83613b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CVD'] ['UniRef90_Protein_Group']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>miss_rate</th>\n",
       "      <th>false_omission_rate</th>\n",
       "      <th>markedness</th>\n",
       "      <th>fall_out</th>\n",
       "      <th>fowlkes_mallows_index</th>\n",
       "      <th>prevalence_threshold</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>threat_score</th>\n",
       "      <th>matthews_correlation_coefficient</th>\n",
       "      <th>false_discovery_rate</th>\n",
       "      <th>negative_predictive_value</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>positive_likelyhood_ratio</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0.873619</td>\n",
       "      <td>0.311358</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.192842</td>\n",
       "      <td>0.369280</td>\n",
       "      <td>0.438430</td>\n",
       "      <td>0.379409</td>\n",
       "      <td>0.987984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.345415</td>\n",
       "      <td>0.805441</td>\n",
       "      <td>0.998283</td>\n",
       "      <td>0.194559</td>\n",
       "      <td>0.630720</td>\n",
       "      <td>0.660305</td>\n",
       "      <td>2.675433</td>\n",
       "      <td>0.082810</td>\n",
       "      <td>0.809352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0.757041</td>\n",
       "      <td>0.076599</td>\n",
       "      <td>0.153381</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.054885</td>\n",
       "      <td>0.406707</td>\n",
       "      <td>0.231302</td>\n",
       "      <td>0.409368</td>\n",
       "      <td>0.846619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062478</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0.936807</td>\n",
       "      <td>0.991692</td>\n",
       "      <td>0.063193</td>\n",
       "      <td>0.593293</td>\n",
       "      <td>0.601245</td>\n",
       "      <td>2.081645</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.719956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_reverse</td>\n",
       "      <td>0.870654</td>\n",
       "      <td>0.181043</td>\n",
       "      <td>0.009661</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.100244</td>\n",
       "      <td>0.394993</td>\n",
       "      <td>0.316202</td>\n",
       "      <td>0.387083</td>\n",
       "      <td>0.990339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100860</td>\n",
       "      <td>0.244295</td>\n",
       "      <td>0.899041</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>0.100959</td>\n",
       "      <td>0.605007</td>\n",
       "      <td>0.621526</td>\n",
       "      <td>2.507234</td>\n",
       "      <td>0.042869</td>\n",
       "      <td>0.797673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_reverse</td>\n",
       "      <td>0.801780</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.045621</td>\n",
       "      <td>0.409146</td>\n",
       "      <td>0.211695</td>\n",
       "      <td>0.399797</td>\n",
       "      <td>0.922139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.152981</td>\n",
       "      <td>0.951401</td>\n",
       "      <td>0.997022</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.590854</td>\n",
       "      <td>0.598196</td>\n",
       "      <td>2.253815</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.756496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment     auroc     auprc  miss_rate  false_omission_rate  \\\n",
       "0           test  0.873619  0.311358   0.012016             0.001717   \n",
       "1          train  0.757041  0.076599   0.153381             0.008308   \n",
       "3   test_reverse  0.870654  0.181043   0.009661             0.000715   \n",
       "4  train_reverse  0.801780  0.066066   0.077861             0.002978   \n",
       "\n",
       "   markedness  fall_out  fowlkes_mallows_index  prevalence_threshold  \\\n",
       "0    0.192842  0.369280               0.438430              0.379409   \n",
       "1    0.054885  0.406707               0.231302              0.409368   \n",
       "3    0.100244  0.394993               0.316202              0.387083   \n",
       "4    0.045621  0.409146               0.211695              0.399797   \n",
       "\n",
       "     recall  ...  threat_score  matthews_correlation_coefficient  \\\n",
       "0  0.987984  ...      0.194100                          0.345415   \n",
       "1  0.846619  ...      0.062478                          0.155386   \n",
       "3  0.990339  ...      0.100860                          0.244295   \n",
       "4  0.922139  ...      0.048400                          0.152981   \n",
       "\n",
       "   false_discovery_rate  negative_predictive_value  precision  specificity  \\\n",
       "0              0.805441                   0.998283   0.194559     0.630720   \n",
       "1              0.936807                   0.991692   0.063193     0.593293   \n",
       "3              0.899041                   0.999285   0.100959     0.605007   \n",
       "4              0.951401                   0.997022   0.048599     0.590854   \n",
       "\n",
       "   accuracy  positive_likelyhood_ratio  prevalence  balanced_accuracy  \n",
       "0  0.660305                   2.675433    0.082810           0.809352  \n",
       "1  0.601245                   2.081645    0.031388           0.719956  \n",
       "3  0.621526                   2.507234    0.042869           0.797673  \n",
       "4  0.598196                   2.253815    0.022162           0.756496  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def independent_edge_evaluation(g, node_types,test_reverse=False):\n",
    "    \n",
    "#     # get the node types we will be predicting edge between\n",
    "#     source_node_type_list = node_types[0]\n",
    "#     destination_node_type_list = node_types[1]\n",
    "    \n",
    "    # get the node types we will be predicting edge between\n",
    "    source_node_type_list = [node_types[0]]\n",
    "    destination_node_type_list = [node_types[1]]\n",
    "    print(source_node_type_list,destination_node_type_list)\n",
    "    \n",
    "    \n",
    "    # split graph into train/test\n",
    "    train, test = g.connected_holdout(train_size=0.7)\n",
    "\n",
    "    # train embedding on train graph\n",
    "    embedding = FirstOrderLINEEnsmallen().fit_transform(train)\n",
    "\n",
    "    # train model on train graph\n",
    "    model = PerceptronEdgePrediction(\n",
    "        edge_features=None,\n",
    "        number_of_edges_per_mini_batch=32,\n",
    "        edge_embeddings=\"CosineSimilarity\"\n",
    "    )\n",
    "    model.fit(\n",
    "        graph=train, \n",
    "        node_features=embedding\n",
    "    )\n",
    "\n",
    "    # predictions for train, test, and negative sampled graph\n",
    "    train_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=train, \n",
    "                                        node_features=embedding, \n",
    "                                        source_node_types = source_node_type_list,\n",
    "                                        destination_node_types = destination_node_type_list,\n",
    "                                        return_predictions_dataframe=True\n",
    "                                    )\n",
    "    test_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=test, \n",
    "                                        node_features=embedding, \n",
    "                                        source_node_types = source_node_type_list,\n",
    "                                        destination_node_types = destination_node_type_list,\n",
    "                                        return_predictions_dataframe=True\n",
    "                                    )\n",
    "    negative_sampled_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(\n",
    "                                    graph=g.sample_negative_graph(number_of_negative_samples=test.get_number_of_edges()),\n",
    "                                    node_features=embedding, \n",
    "                                    source_node_types = source_node_type_list,\n",
    "                                    destination_node_types = destination_node_type_list,\n",
    "                                    return_predictions_dataframe=True\n",
    "                                )\n",
    "\n",
    "    # label predictions\n",
    "    labeled_train_pred_df = label_predictions_with_ground_truth(train_pred_df,train)\n",
    "    labeled_test_pred_df = label_predictions_with_ground_truth(test_pred_df,test)\n",
    "    labeled_negative_sample_pred_df = label_negative_sample_pred(negative_sampled_pred_df)\n",
    "    \n",
    "    # evaluation\n",
    "    data = [evaluate_predictions(model,labeled_train_pred_df),\n",
    "            evaluate_predictions(model,labeled_test_pred_df),\n",
    "            evaluate_predictions(model,labeled_negative_sample_pred_df)]\n",
    "    eval_df = pd.DataFrame(data)\n",
    "    \n",
    "    ''' REVERSE '''\n",
    "    # swapping source and destination nodes results in different results...\n",
    "    if test_reverse:\n",
    "        # predictions for train, test, and negative sampled graph\n",
    "        train_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=train, \n",
    "                                            node_features=embedding, \n",
    "                                            source_node_types = destination_node_type_list,\n",
    "                                            destination_node_types = source_node_type_list,\n",
    "                                            return_predictions_dataframe=True\n",
    "                                        )\n",
    "        test_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=test, \n",
    "                                            node_features=embedding, \n",
    "                                            source_node_types = destination_node_type_list,\n",
    "                                            destination_node_types = source_node_type_list,\n",
    "                                            return_predictions_dataframe=True\n",
    "                                        )\n",
    "        negative_sampled_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(\n",
    "                                        graph=g.sample_negative_graph(number_of_negative_samples=test.get_number_of_edges()),\n",
    "                                        node_features=embedding, \n",
    "                                        source_node_types = destination_node_type_list,\n",
    "                                        destination_node_types = source_node_type_list,\n",
    "                                        return_predictions_dataframe=True\n",
    "                                    )\n",
    "\n",
    "        # label predictions\n",
    "        labeled_train_pred_df = label_predictions_with_ground_truth(train_pred_df,train)\n",
    "        labeled_test_pred_df = label_predictions_with_ground_truth(test_pred_df,test)\n",
    "        labeled_negative_sample_pred_df = label_negative_sample_pred(negative_sampled_pred_df)\n",
    "\n",
    "        # evaluation\n",
    "        data += [evaluate_predictions(model,labeled_train_pred_df)]\n",
    "        data += [evaluate_predictions(model,labeled_test_pred_df)]\n",
    "        data += [evaluate_predictions(model,labeled_negative_sample_pred_df)]\n",
    "        \n",
    "    # convert to dataframe\n",
    "    eval_df = pd.DataFrame(data)\n",
    "    \n",
    "    # add experiment column\n",
    "    experiments = ['test','train','negative_sample']\n",
    "    if test_reverse:\n",
    "        experiments += [h+\"_reverse\" for h in experiments]\n",
    "    eval_df.insert(loc=0, column='experiment', value=experiments)\n",
    "    \n",
    "    return eval_df\n",
    "\n",
    "temp_df = independent_edge_evaluation(g,edge_type_to_node_types_mapping['CaseOLAP_score'][0], test_reverse=True)\n",
    "temp_df.drop([2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de5bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e39e2f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CVD'] ['UniRef90_Protein_Group']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>specificity</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>informedness</th>\n",
       "      <th>miss_rate</th>\n",
       "      <th>positive_likelyhood_ratio</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prevalence_threshold</th>\n",
       "      <th>...</th>\n",
       "      <th>false_omission_rate</th>\n",
       "      <th>negative_likelyhood_ratio</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>false_discovery_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>threat_score</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>fowlkes_mallows_index</th>\n",
       "      <th>matthews_correlation_coefficient</th>\n",
       "      <th>diagnostic_odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0.896688</td>\n",
       "      <td>0.491091</td>\n",
       "      <td>0.661217</td>\n",
       "      <td>0.455039</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>2.918377</td>\n",
       "      <td>0.702374</td>\n",
       "      <td>0.369232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.017096</td>\n",
       "      <td>0.125679</td>\n",
       "      <td>0.704473</td>\n",
       "      <td>0.988696</td>\n",
       "      <td>0.294531</td>\n",
       "      <td>0.824956</td>\n",
       "      <td>0.540542</td>\n",
       "      <td>0.436433</td>\n",
       "      <td>170.702600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0.783484</td>\n",
       "      <td>0.142040</td>\n",
       "      <td>0.605436</td>\n",
       "      <td>0.198423</td>\n",
       "      <td>0.483631</td>\n",
       "      <td>0.121805</td>\n",
       "      <td>2.225734</td>\n",
       "      <td>0.620042</td>\n",
       "      <td>0.401302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.201185</td>\n",
       "      <td>0.053550</td>\n",
       "      <td>0.888153</td>\n",
       "      <td>0.878195</td>\n",
       "      <td>0.110138</td>\n",
       "      <td>0.741816</td>\n",
       "      <td>0.313406</td>\n",
       "      <td>0.220566</td>\n",
       "      <td>11.063125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_reverse</td>\n",
       "      <td>0.896688</td>\n",
       "      <td>0.491092</td>\n",
       "      <td>0.661217</td>\n",
       "      <td>0.455039</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>2.918377</td>\n",
       "      <td>0.702374</td>\n",
       "      <td>0.369232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.017096</td>\n",
       "      <td>0.125679</td>\n",
       "      <td>0.704473</td>\n",
       "      <td>0.988696</td>\n",
       "      <td>0.294531</td>\n",
       "      <td>0.824956</td>\n",
       "      <td>0.540542</td>\n",
       "      <td>0.436433</td>\n",
       "      <td>170.702600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_reverse</td>\n",
       "      <td>0.783484</td>\n",
       "      <td>0.142040</td>\n",
       "      <td>0.605436</td>\n",
       "      <td>0.198423</td>\n",
       "      <td>0.483631</td>\n",
       "      <td>0.121805</td>\n",
       "      <td>2.225734</td>\n",
       "      <td>0.620042</td>\n",
       "      <td>0.401302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.201185</td>\n",
       "      <td>0.053550</td>\n",
       "      <td>0.888153</td>\n",
       "      <td>0.878195</td>\n",
       "      <td>0.110138</td>\n",
       "      <td>0.741816</td>\n",
       "      <td>0.313406</td>\n",
       "      <td>0.220566</td>\n",
       "      <td>11.063125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment     auroc     auprc  specificity  f1_score  informedness  \\\n",
       "0           test  0.896688  0.491091     0.661217  0.455039      0.649913   \n",
       "1          train  0.783484  0.142040     0.605436  0.198423      0.483631   \n",
       "3   test_reverse  0.896688  0.491092     0.661217  0.455039      0.649913   \n",
       "4  train_reverse  0.783484  0.142040     0.605436  0.198423      0.483631   \n",
       "\n",
       "   miss_rate  positive_likelyhood_ratio  accuracy  prevalence_threshold  ...  \\\n",
       "0   0.011304                   2.918377  0.702374              0.369232  ...   \n",
       "1   0.121805                   2.225734  0.620042              0.401302  ...   \n",
       "3   0.011304                   2.918377  0.702374              0.369232  ...   \n",
       "4   0.121805                   2.225734  0.620042              0.401302  ...   \n",
       "\n",
       "   false_omission_rate  negative_likelyhood_ratio  prevalence  \\\n",
       "0             0.002451                   0.017096    0.125679   \n",
       "1             0.011255                   0.201185    0.053550   \n",
       "3             0.002451                   0.017096    0.125679   \n",
       "4             0.011255                   0.201185    0.053550   \n",
       "\n",
       "   false_discovery_rate    recall  threat_score  balanced_accuracy  \\\n",
       "0              0.704473  0.988696      0.294531           0.824956   \n",
       "1              0.888153  0.878195      0.110138           0.741816   \n",
       "3              0.704473  0.988696      0.294531           0.824956   \n",
       "4              0.888153  0.878195      0.110138           0.741816   \n",
       "\n",
       "   fowlkes_mallows_index  matthews_correlation_coefficient  \\\n",
       "0               0.540542                          0.436433   \n",
       "1               0.313406                          0.220566   \n",
       "3               0.540542                          0.436433   \n",
       "4               0.313406                          0.220566   \n",
       "\n",
       "   diagnostic_odds_ratio  \n",
       "0             170.702600  \n",
       "1              11.063125  \n",
       "3             170.702600  \n",
       "4              11.063125  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_predictions_with_ground_truth(pred_df, test_graph, return_bool = True, directed=False):\n",
    "    test_edges = set(test_graph.get_edge_node_names(directed=False))\n",
    "    # consider reverse edges if directed is False\n",
    "    if not directed:\n",
    "        test_edges = test_edges.union([(t,f) for (f,t) in test_edges])\n",
    "    \n",
    "    # convert to dataframe to label edges\n",
    "    test_edges_df = pd.DataFrame(test_edges)\n",
    "    test_edges_df.columns = ['sources','destinations']\n",
    "    \n",
    "    labeled_pred_df = pred_df.merge(test_edges_df,how='left',indicator=True)\n",
    "    test_truth = []\n",
    "    for b in labeled_pred_df['_merge'] == 'both':\n",
    "        if return_bool:\n",
    "            y_ = b\n",
    "        else:\n",
    "            # return 1 or 0\n",
    "            y_ = 1 if b else 0\n",
    "        test_truth += [y_]\n",
    "    labeled_pred_df['ground_truth'] = test_truth\n",
    "    labeled_pred_df = labeled_pred_df.drop('_merge', axis=1)\n",
    "    return labeled_pred_df\n",
    "\n",
    "\n",
    "temp_df = independent_edge_evaluation(g,edge_type_to_node_types_mapping['CaseOLAP_score'][0], test_reverse=True)\n",
    "temp_df.drop([2,5])\n",
    "# labeled_rev_train_pred_df = label_predictions_with_ground_truth(rev_train_pred_df,train,directed=False)\n",
    "# labeled_rev_train_pred_df[labeled_rev_train_pred_df['ground_truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525b6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e42de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193411e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b048e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f78ecd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>threat_score</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fowlkes_mallows_index</th>\n",
       "      <th>negative_predictive_value</th>\n",
       "      <th>markedness</th>\n",
       "      <th>informedness</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>...</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>positive_likelyhood_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>prevalence_threshold</th>\n",
       "      <th>recall</th>\n",
       "      <th>false_omission_rate</th>\n",
       "      <th>diagnostic_odds_ratio</th>\n",
       "      <th>precision</th>\n",
       "      <th>negative_likelyhood_ratio</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0.873595</td>\n",
       "      <td>0.311321</td>\n",
       "      <td>0.194144</td>\n",
       "      <td>0.630858</td>\n",
       "      <td>0.438468</td>\n",
       "      <td>0.998273</td>\n",
       "      <td>0.192880</td>\n",
       "      <td>0.618772</td>\n",
       "      <td>0.325160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082810</td>\n",
       "      <td>2.676245</td>\n",
       "      <td>0.809386</td>\n",
       "      <td>0.379374</td>\n",
       "      <td>0.987914</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>139.694813</td>\n",
       "      <td>0.194606</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.660426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0.756981</td>\n",
       "      <td>0.076565</td>\n",
       "      <td>0.062512</td>\n",
       "      <td>0.593436</td>\n",
       "      <td>0.231389</td>\n",
       "      <td>0.991704</td>\n",
       "      <td>0.054931</td>\n",
       "      <td>0.440238</td>\n",
       "      <td>0.117668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>2.082826</td>\n",
       "      <td>0.720119</td>\n",
       "      <td>0.409299</td>\n",
       "      <td>0.846802</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>8.068157</td>\n",
       "      <td>0.063227</td>\n",
       "      <td>0.258154</td>\n",
       "      <td>0.601389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative_sample</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment     auroc     auprc  threat_score  specificity  \\\n",
       "0             test  0.873595  0.311321      0.194144     0.630858   \n",
       "1            train  0.756981  0.076565      0.062512     0.593436   \n",
       "2  negative_sample       NaN       NaN      0.000000     0.579618   \n",
       "\n",
       "   fowlkes_mallows_index  negative_predictive_value  markedness  informedness  \\\n",
       "0               0.438468                   0.998273    0.192880      0.618772   \n",
       "1               0.231389                   0.991704    0.054931      0.440238   \n",
       "2                    NaN                   1.000000    0.000000           NaN   \n",
       "\n",
       "   f1_score  ...  prevalence  positive_likelyhood_ratio  balanced_accuracy  \\\n",
       "0  0.325160  ...    0.082810                   2.676245           0.809386   \n",
       "1  0.117668  ...    0.031388                   2.082826           0.720119   \n",
       "2  0.000000  ...    0.000000                        NaN                NaN   \n",
       "\n",
       "   prevalence_threshold    recall  false_omission_rate  diagnostic_odds_ratio  \\\n",
       "0              0.379374  0.987914             0.001727             139.694813   \n",
       "1              0.409299  0.846802             0.008296               8.068157   \n",
       "2                   NaN       NaN             0.000000                    NaN   \n",
       "\n",
       "   precision  negative_likelyhood_ratio  accuracy  \n",
       "0   0.194606                   0.019158  0.660426  \n",
       "1   0.063227                   0.258154  0.601389  \n",
       "2   0.000000                        NaN  0.579618  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "from grape import Graph\n",
    "import pandas as pd\n",
    "\n",
    "from grape.edge_prediction import PerceptronEdgePrediction\n",
    "from grape.embedders import FirstOrderLINEEnsmallen\n",
    "\n",
    "def label_predictions_with_ground_truth(pred_df, test_graph, return_bool = True):\n",
    "    test_edges = pd.DataFrame(test_graph.get_edge_node_names(directed=False))\n",
    "    test_edges.columns = ['sources','destinations']\n",
    "    \n",
    "    labeled_pred_df = pred_df.merge(test_edges,how='left',indicator=True)\n",
    "    test_truth = []\n",
    "    for b in labeled_pred_df['_merge'] == 'both':\n",
    "        if return_bool:\n",
    "            y_ = b\n",
    "        else:\n",
    "            # return 1 or 0\n",
    "            y_ = 1 if b else 0\n",
    "        test_truth += [y_]\n",
    "    labeled_pred_df['ground_truth'] = test_truth\n",
    "    labeled_pred_df = labeled_pred_df.drop('_merge', axis=1)\n",
    "    return labeled_pred_df\n",
    "\n",
    "\n",
    "def label_negative_sample_pred(pred_df):\n",
    "    pred_df['ground_truth'] = False\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def evaluate_predictions(m, labeled_pred_df):\n",
    "    # convert DataFrame to numpy used for evaluation\n",
    "    y_label = labeled_pred_df['ground_truth'].to_numpy()\n",
    "    y_score = labeled_pred_df['predictions'].to_numpy()\n",
    "    \n",
    "    # handle case where no ground truth (for negative sampled edges)\n",
    "    all_false = len(set(y_label)) == 1 and (~y_label[0])\n",
    "    if all_false:\n",
    "        e1 = {'auroc':float('NaN'),'auprc':float('NaN')}\n",
    "    else:\n",
    "        e1 = m.evaluate_prediction_probabilities(y_label,y_score)\n",
    "    e2 = m.evaluate_predictions(y_label,y_score)\n",
    "    return e1 | e2\n",
    "\n",
    "def independent_edge_evaluation(g, node_types):\n",
    "    \n",
    "    # get the node types we will be predicting edge between\n",
    "    source_node_type_list = [node_types[0]] # these need to be in a list for grape\n",
    "    destination_node_type_list = [node_types[1]]\n",
    "    \n",
    "    # split graph into train/test\n",
    "    train, test = g.connected_holdout(train_size=0.7)\n",
    "\n",
    "    # train embedding on train graph\n",
    "    embedding = FirstOrderLINEEnsmallen().fit_transform(train)\n",
    "\n",
    "    # train model on train graph\n",
    "    model = PerceptronEdgePrediction(\n",
    "        edge_features=None,\n",
    "        number_of_edges_per_mini_batch=32,\n",
    "        edge_embeddings=\"CosineSimilarity\"\n",
    "    )\n",
    "    model.fit(\n",
    "        graph=train, \n",
    "        node_features=embedding\n",
    "    )\n",
    "    \n",
    "    # predictions for train, test, and negative sampled graph\n",
    "    train_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=train, \n",
    "                                        node_features=embedding, \n",
    "                                        source_node_types = source_node_type_list,\n",
    "                                        destination_node_types = destination_node_type_list,\n",
    "                                        return_predictions_dataframe=True\n",
    "                                    )\n",
    "    test_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=test, \n",
    "                                        node_features=embedding, \n",
    "                                        source_node_types = source_node_type_list,\n",
    "                                        destination_node_types = destination_node_type_list,\n",
    "                                        return_predictions_dataframe=True\n",
    "                                    )\n",
    "    negative_sampled_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(\n",
    "                                    graph=g.sample_negative_graph(number_of_negative_samples=test.get_number_of_edges()),\n",
    "                                    node_features=embedding, \n",
    "                                    source_node_types = source_node_type_list,\n",
    "                                    destination_node_types = destination_node_type_list,\n",
    "                                    return_predictions_dataframe=True\n",
    "                                )\n",
    "    \n",
    "    # label predictions\n",
    "    labeled_train_pred_df = label_predictions_with_ground_truth(train_pred_df,train)\n",
    "    labeled_test_pred_df = label_predictions_with_ground_truth(test_pred_df,test)\n",
    "    labeled_negative_sample_pred_df = label_negative_sample_pred(negative_sampled_pred_df)\n",
    "    \n",
    "    # evaluation\n",
    "    data = [evaluate_predictions(model,labeled_train_pred_df),\n",
    "            evaluate_predictions(model,labeled_test_pred_df),\n",
    "            evaluate_predictions(model,labeled_negative_sample_pred_df)]\n",
    "    eval_df = pd.DataFrame(data)\n",
    "    \n",
    "    # add experiment column\n",
    "    experiments = ['test','train','negative_sample']\n",
    "    eval_df.insert(loc=0, column='experiment', value=experiments)\n",
    "    \n",
    "    return eval_df\n",
    "\n",
    "# load graph\n",
    "g = Graph.from_csv(\n",
    "  directed=False, \n",
    "  node_path='merged_nodes.tsv',\n",
    "  edge_path='merged_edges.tsv',\n",
    "  verbose=True,\n",
    "  nodes_column='node',\n",
    "  node_list_node_types_column='node_type',\n",
    "  default_node_type='None',\n",
    "  sources_column='head',\n",
    "  destinations_column='tail',\n",
    "  edge_list_edge_types_column='edge_type',\n",
    "  name=\"CVD KG\"\n",
    ")\n",
    "g = g.remove_disconnected_nodes()\n",
    "\n",
    "# load edge types\n",
    "edge_type_to_node_types_mapping = get_edge_type_to_node_types_mapping(g,directed=False)\n",
    "\n",
    "# compute edge evaluation for \n",
    "edge_pair = edge_type_to_node_types_mapping['CaseOLAP_score'][0]\n",
    "independent_edge_evaluation(g,edge_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f960cbe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pykeen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19381/1985275257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0membiggen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLEEEnsmallen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0membiggen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHOPEEnsmallen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0membiggen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpykeen_embedders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistmult\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistMultPyKEEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0membiggen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpykeen_embedders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhole\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHolEPyKEEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/embiggen/embedders/pykeen_embedders/distmult.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Submodule providing wrapper for PyKEEN's DistMult model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpykeen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingLoop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpykeen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistMult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0membiggen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpykeen_embedders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_relation_embedding_model_pykeen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEntityRelationEmbeddingModelPyKEEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pykeen'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from grape import Graph\n",
    "\n",
    "# node embedding imports\n",
    "from embiggen.embedders.ensmallen_embedders.degree_spine import DegreeSPINE\n",
    "from embiggen.embedders import GLEEEnsmallen\n",
    "from embiggen.embedders import HOPEEnsmallen\n",
    "from embiggen.embedders.pykeen_embedders.distmult import DistMultPyKEEN\n",
    "from embiggen.embedders.pykeen_embedders.hole import HolEPyKEEN\n",
    "\n",
    "# edge prediction imports\n",
    "from embiggen.edge_prediction.edge_prediction_model import AbstractEdgePredictionModel\n",
    "from grape.edge_prediction import PerceptronEdgePrediction\n",
    "from grape.edge_prediction import MLPEdgePrediction\n",
    "from grape.edge_prediction import GNNEdgePrediction\n",
    "\n",
    "\n",
    "def label_predictions_with_ground_truth(pred_df, test_graph, return_bool = True):\n",
    "    test_edges = pd.DataFrame(test_graph.get_edge_node_names(directed=False))\n",
    "    test_edges.columns = ['sources','destinations']\n",
    "    \n",
    "    labeled_pred_df = pred_df.merge(test_edges,how='left',indicator=True)\n",
    "    test_truth = []\n",
    "    for b in labeled_pred_df['_merge'] == 'both':\n",
    "        if return_bool:\n",
    "            y_ = b\n",
    "        else:\n",
    "            # return 1 or 0\n",
    "            y_ = 1 if b else 0\n",
    "        test_truth += [y_]\n",
    "    labeled_pred_df['ground_truth'] = test_truth\n",
    "    labeled_pred_df = labeled_pred_df.drop('_merge', axis=1)\n",
    "    return labeled_pred_df\n",
    "\n",
    "\n",
    "def label_negative_sample_pred(pred_df):\n",
    "    pred_df['ground_truth'] = False\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def evaluate_predictions(m, labeled_pred_df):\n",
    "    # convert DataFrame to numpy used for evaluation\n",
    "    y_label = labeled_pred_df['ground_truth'].to_numpy()\n",
    "    y_score = labeled_pred_df['predictions'].to_numpy()\n",
    "    \n",
    "    # handle case where no ground truth (for negative sampled edges)\n",
    "    all_false = len(set(y_label)) == 1 and (~y_label[0])\n",
    "    if all_false:\n",
    "        e1 = {'auroc':float('NaN'),'auprc':float('NaN')}\n",
    "    else:\n",
    "        e1 = m.evaluate_prediction_probabilities(y_label,y_score)\n",
    "    e2 = m.evaluate_predictions(y_label,y_score)\n",
    "    return e1 | e2\n",
    "\n",
    "def get_edge_type_to_node_types_mapping(g, directed=False):\n",
    "    '''\n",
    "    This function returns a mapping from edge_type -> (from_types,to_types)\n",
    "    '''\n",
    "    # gather node and edge types for every edge as a DataFrame\n",
    "    edge_to_type_dict = {h:[] for h in [\"from\",\"to\",\"from_type\",\"to_type\",\"edge_type\"]}\n",
    "    for from_node_id,to_node_id in g.get_edge_node_ids(directed=False):\n",
    "        # get node types\n",
    "        from_node_type_ids = g.get_node_type_ids_from_node_id(from_node_id)\n",
    "        from_node_type = [g.get_node_type_name_from_node_type_id(i) for i in from_node_type_ids]\n",
    "        to_node_type_ids = g.get_node_type_ids_from_node_id(to_node_id)\n",
    "        to_node_type =  [g.get_node_type_name_from_node_type_id(i) for i in to_node_type_ids]\n",
    "\n",
    "        # get edge type\n",
    "        edge_id = g.get_edge_id_from_node_ids(from_node_id,to_node_id)\n",
    "        edge_type = g.get_edge_type_name_from_edge_id(edge_id)\n",
    "\n",
    "        # append to dict\n",
    "        edge_to_type_dict['from'] += [from_node_id]\n",
    "        edge_to_type_dict['to'] += [to_node_id]\n",
    "        edge_to_type_dict['from_type'] += [from_node_type]\n",
    "        edge_to_type_dict['to_type'] += [to_node_type]\n",
    "        edge_to_type_dict['edge_type'] += [edge_type]\n",
    "    edge_to_type_df = pd.DataFrame(edge_to_type_dict)\n",
    "\n",
    "    # take unique node types for each edge type\n",
    "    edge_type_to_node_types = {}\n",
    "    for edge_type in set(edge_to_type_df['edge_type']):\n",
    "        # only rows with the specified edge_type\n",
    "        sub_df = edge_to_type_df[edge_to_type_df['edge_type'] == edge_type]\n",
    "        \n",
    "        # get unique pairs of node types\n",
    "        unique_node_type_pairs = set()\n",
    "        for from_node_types, to_node_types in zip(sub_df['from_type'],sub_df['to_type']):\n",
    "            # enumerate all pairs, since these are lists of node types\n",
    "            pairs = [(f,t) for f in from_node_types for t in to_node_types]\n",
    "            \n",
    "            # if undirected, do not include reverse node type \n",
    "            # i.e. include (type_1,type_2) but not (type_2,type_1)\n",
    "            if not directed:                \n",
    "                pairs_sorted = set()\n",
    "                for f,t in pairs:\n",
    "                    # sort pair alphabetically\n",
    "                    pair = (f,t) if (f < t) else (t,f) \n",
    "                    # keep unique pairs\n",
    "                    pairs_sorted.add(pair)\n",
    "                pairs = pairs_sorted\n",
    "                \n",
    "            # add unique pairs\n",
    "            unique_node_type_pairs = unique_node_type_pairs.union(pairs)\n",
    "            \n",
    "        edge_type_to_node_types[edge_type] = list(unique_node_type_pairs)\n",
    "    return edge_type_to_node_types\n",
    "\n",
    "\n",
    "subgraph_description_file = \"./subgraphs/subgraphs_summary.tsv\"\n",
    "results_table_file_name = \"./2022-09-20_independent_evaluation_results_table.csv\"\n",
    "\n",
    "# file listing all sub-graphs to test\n",
    "subgraph_df = pd.read_csv(subgraph_description_file,sep=\"\\t\")\n",
    "\n",
    "for node_path, edge_path, kg_description, kg_num in zip(subgraph_df['Node file'],\n",
    "                                                        subgraph_df['Edge file'],\n",
    "                                                        subgraph_df['Resources Included'],\n",
    "                                                        subgraph_df['Experiment Number']):\n",
    "    kg_name = 'CKG %d: %s'%(kg_num,kg_description)\n",
    "\n",
    "    # load graph\n",
    "    g = Graph.from_csv(\n",
    "      directed=False,\n",
    "      node_path=node_path,\n",
    "      edge_path=edge_path,\n",
    "      verbose=True,\n",
    "      nodes_column='id',\n",
    "      node_list_node_types_column='category',\n",
    "      default_node_type='None',\n",
    "      sources_column='subject',\n",
    "      destinations_column='object',\n",
    "      edge_list_edge_types_column='predicate',\n",
    "      weights_column = 'score',\n",
    "      default_weight=1.0,\n",
    "      name=kg_name\n",
    "    )\n",
    "    g = g.remove_disconnected_nodes()\n",
    "    \n",
    "    # split graph into train/test\n",
    "    train, test = g.connected_holdout(train_size=0.7)\n",
    "\n",
    "    # load edge types\n",
    "    edge_type_to_node_types_mapping = get_edge_type_to_node_types_mapping(g,directed=False)\n",
    "    # to compute edge evaluation only for CaseOLAP_score edges\n",
    "    edge_pair = edge_type_to_node_types_mapping['CaseOLAP_score'][0]\n",
    "    \n",
    "    # train all node embeddings\n",
    "    embedding_models = {'SPINE':DegreeSPINE().fit_transform(train),\n",
    "                    'GLEE':GLEEEnsmallen().fit_transform(train),\n",
    "                    'HOPE':HOPEEnsmallen().fit_transform(train),\n",
    "                    'DistMultPyKEEN':DistMultPyKEEN().fit_transform(train),\n",
    "                    'HolEPyKEEN':HolEPyKEEN().fit_transform(train)}\n",
    "    \n",
    "    # store results of gridsearch here\n",
    "    results_df = None\n",
    "\n",
    "    # grid search over node embedding models \n",
    "    for node_embedding_model_name,embedding in node_models.items():\n",
    "                \n",
    "        # grid search over edge prediction models\n",
    "        edge_prediciton_models = {'Perceptron': PerceptronEdgePrediction(edge_features=None,\n",
    "                                           number_of_edges_per_mini_batch=32,\n",
    "                                           edge_embeddings=\"CosineSimilarity\"),\n",
    "                                  'MLP': MLPEdgePrediction(edge_features=None,\n",
    "                                           number_of_edges_per_mini_batch=32,\n",
    "                                           edge_embeddings=\"CosineSimilarity\"),\n",
    "                                  'GNN': GNNEdgePrediction(edge_features=None,\n",
    "                                           number_of_edges_per_mini_batch=32,\n",
    "                                           edge_embeddings=\"CosineSimilarity\")}\n",
    "        \n",
    "        for edge_pred_model_name, model in edge_prediciton_models.items():\n",
    "            \n",
    "            # train model\n",
    "            model.fit(\n",
    "                graph=train, \n",
    "                node_features=embedding\n",
    "            )\n",
    "            \n",
    "            # predictions for train, test, and negative sampled graph\n",
    "            train_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=train, \n",
    "                                                node_features=embedding, \n",
    "                                                source_node_types = source_node_type_list,\n",
    "                                                destination_node_types = destination_node_type_list,\n",
    "                                                return_predictions_dataframe=True\n",
    "                                            )\n",
    "            test_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(graph=test, \n",
    "                                                node_features=embedding, \n",
    "                                                source_node_types = source_node_type_list,\n",
    "                                                destination_node_types = destination_node_type_list,\n",
    "                                                return_predictions_dataframe=True\n",
    "                                            )\n",
    "            negative_sampled_pred_df = model.predict_proba_bipartite_graph_from_edge_node_types(\n",
    "                                            graph=g.sample_negative_graph(number_of_negative_samples=test.get_number_of_edges()),\n",
    "                                            node_features=embedding, \n",
    "                                            source_node_types = source_node_type_list,\n",
    "                                            destination_node_types = destination_node_type_list,\n",
    "                                            return_predictions_dataframe=True\n",
    "                                        )\n",
    "\n",
    "            # label predictions\n",
    "            labeled_train_pred_df = label_predictions_with_ground_truth(train_pred_df,train)\n",
    "            labeled_test_pred_df = label_predictions_with_ground_truth(test_pred_df,test)\n",
    "            labeled_negative_sample_pred_df = label_negative_sample_pred(negative_sampled_pred_df)\n",
    "\n",
    "            # evaluation\n",
    "            data = [evaluate_predictions(model,labeled_train_pred_df),\n",
    "                    evaluate_predictions(model,labeled_test_pred_df),\n",
    "                    evaluate_predictions(model,labeled_negative_sample_pred_df)]\n",
    "            \n",
    "            \n",
    "            ### Make result dataframe ###\n",
    "            eval_df = pd.DataFrame(data)\n",
    "\n",
    "            # add experiment column\n",
    "            experiments = ['test','train','negative_sample']\n",
    "            eval_df.insert(loc=0, column='experiment', value=experiments)\n",
    "            \n",
    "            # add edge prediction and node embedding models\n",
    "            eval_df.insert(loc=0, column='edge_prediction_model', value = edge_pred_model_name)\n",
    "            eval_df.insert(loc=0, column='node_embedding', value = node_embedding_model_name)\n",
    "            \n",
    "            # add kg graph name\n",
    "            eval_df.insert(loc=0, column='graph_name', value = kg_name)\n",
    "            \n",
    "            # store and save results into one big table\n",
    "            if not results_df:\n",
    "                results_df = eval_df\n",
    "            # append new results\n",
    "            results_df = results_df.append(eval_df, ignore_index = True)\n",
    "            results_df.to_csv(results_table_file_name)\n",
    "            \n",
    "            exp_tag = \"kg: %s, node_emb: %s, edge_pred_model: %s\"%(kg_name,\n",
    "                                                                   node_embedding_model_name,\n",
    "                                                                   ege_pred_model_name)\n",
    "            print(\"Finished %s\"%exp_tag)\n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.edge_prediction import PerceptronEdgePrediction\n",
    "from grape.edge_prediction import MLPEdgePrediction\n",
    "from grape.edge_prediction import GNNEdgePrediction\n",
    "\n",
    "from embiggen import get_available_models_for_edge_prediction, get_available_models_for_node_embedding\n",
    "from embiggen.edge_prediction.edge_prediction_model import AbstractEdgePredictionModel\n",
    "get_available_models_for_edge_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
